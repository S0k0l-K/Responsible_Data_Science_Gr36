{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3959cbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.system('pip3 install Seaborn')\n",
    "os.system('pip3 install xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b3b542e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Load in all the data\n",
    "samplesubmission = pd.read_csv('data/samplesubmission.csv')\n",
    "solution_template = pd.read_csv('data/solution_template.csv')\n",
    "training = pd.read_csv('data/training_v2.csv')\n",
    "unlabeled = pd.read_csv('data/unlabeled.csv')\n",
    "wids = pd.read_csv('data/WiDS_Datathon_2020_Dictionary.csv')\n",
    "\n",
    "# CSV files must be in folder called 'data' in the same directory as the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "101596a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encounter_id             91713\n",
       "patient_id               91713\n",
       "bmi                      34888\n",
       "urineoutput_apache       24772\n",
       "pre_icu_los_days          9757\n",
       "                         ...  \n",
       "gcs_unable_apache            2\n",
       "elective_surgery             2\n",
       "gender                       2\n",
       "apache_post_operative        2\n",
       "readmission_status           1\n",
       "Length: 186, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all the categorical features and set them to their appropriate type\n",
    "\n",
    "num_unique_values = training.nunique().sort_values(ascending=False)\n",
    "display(num_unique_values)\n",
    "# After manually inspecting it seems that hospital_admit_source is the last categorical feature\n",
    "# So we'll convert all columns with less unique values to a categorical feature as well\n",
    "categorical_features = num_unique_values[num_unique_values <= 15].index\n",
    "training_typed = training.astype(dict(zip(categorical_features, ['category'] * len(categorical_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0227e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the percentage of non missing values for each feature\n",
    "missing = (training_typed.notna().sum() / len(training)) * 100\n",
    "\n",
    "# Looking at the data there is a big gap in data availability between wbc_apache and urineoutput_apache, namely 75% and then 46%\n",
    "# To make analysis easier we'll only consider features with more than 50% data availability\n",
    "chosen_features = list(missing[missing > 50].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db0293c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = training_typed[chosen_features].fillna(training_typed[chosen_features].mean(numeric_only=True))\n",
    "df_training = df_training.loc[(df_training['temp_apache'] >= 15) & (df_training['temp_apache'] <= 45) & (df_training['h1_temp_min'] >= 15) & (df_training['h1_temp_max'] <= 45)]\n",
    "# df_training.select_dtypes(include=['category'])\n",
    "# df_final = pd.get_dummies(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "41241eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 # proportion for train versus test+val split\n",
    "val_size = 0.5 # proportion for test versus val split\n",
    "random_state = 42  # random state is used to set a seed for randomness, which is only relevant for reproducibility purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b83824dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_training.copy().drop(['hospital_death', 'patient_id', 'encounter_id', 'hospital_id', 'icu_id', # drop identifiers\n",
    "                    'd1_diasbp_noninvasive_max', 'd1_diasbp_noninvasive_min', 'd1_mbp_noninvasive_max', 'd1_mbp_noninvasive_min', 'd1_sysbp_noninvasive_max', 'd1_sysbp_noninvasive_min', # drop high correlation vitals\n",
    "                    'h1_diasbp_noninvasive_max', 'h1_diasbp_noninvasive_min', 'h1_mbp_noninvasive_max', 'h1_mbp_noninvasive_min', 'h1_sysbp_noninvasive_max', 'h1_sysbp_noninvasive_min', # drop high correlation vitals\n",
    "                    'height','weight','d1_bun_min','d1_bun_max','d1_creatinine_min','d1_creatinine_max','d1_glucose_max','d1_hemaglobin_max','d1_hemaglobin_min','d1_hematocrit_max','d1_hematocrit_min','d1_sodium_max','d1_sodium_min','d1_wbc_max','d1_wbc_min', # drop correlated features\n",
    "                    'apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob'], # drop APACHE scores\n",
    "                   axis=1)\n",
    "y = df_training['hospital_death'].copy()\n",
    "y_apache = df_training['apache_4a_hospital_death_prob'].copy()\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# split the dataset into train and test+validation set\n",
    "(X_train, X_test,\n",
    " y_train, y_test,\n",
    " y_apache_train, y_apache_test\n",
    ") = train_test_split(X, y, y_apache, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# split the test set into test + validation set\n",
    "(X_val, X_test,\n",
    " y_val, y_test,\n",
    " y_apache_val, y_apache_test,\n",
    ") = train_test_split(X_test, y_test, y_apache_test, test_size=val_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1acf4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing sensitive features from the training data\n",
    "sensitive_features = ['ethnicity_Asian', 'ethnicity_Caucasian', 'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown',\n",
    "                      'gender_M', 'age']\n",
    "X_train.drop(sensitive_features, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ea6c6cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Recall: 0.21871049304677623\n",
      "LG Recall: 0.20733249051833122\n",
      "XGB Recall: 0.3059418457648546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      8381\n",
      "           1       0.71      0.22      0.33       791\n",
      "\n",
      "    accuracy                           0.92      9172\n",
      "   macro avg       0.82      0.61      0.65      9172\n",
      "weighted avg       0.91      0.92      0.91      9172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "k_best_selector = SelectKBest(score_func=f_classif, k=50)\n",
    "k_best_selector.fit(X_train, y_train)\n",
    "selected_feature_indices = k_best_selector.get_support(indices=True)\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "sensitive_features = ['ethnicity_Asian', 'ethnicity_Caucasian', 'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown',\n",
    "                      'gender_M', 'age']\n",
    "\n",
    "all_features = sensitive_features + selected_features.tolist()\n",
    "all_features = list(set(all_features))\n",
    "\n",
    "X_train = X_train.loc[:, all_features]\n",
    "X_test = X_test.loc[:, all_features]\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "print(f\"RFC Recall: {recall_score(y_test, rfc.predict(X_test))}\")\n",
    "\n",
    "lg = LogisticRegression(solver='liblinear')\n",
    "lg.fit(X_train, y_train)\n",
    "print(f\"LG Recall: {recall_score(y_test, lg.predict(X_test))}\")\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "print(f\"XGB Recall: {recall_score(y_test, xgb.predict(X_test))}\")\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13610200",
   "metadata": {},
   "source": [
    "Recall, F1 and Area Under ROC for Ethnic Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "33d88b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnicity: Asian\n",
      "RFC Recall: 0.4\n",
      "LG Recall: 0.4\n",
      "XGB Recall: 0.5\n",
      "Ethnicity: Caucasian\n",
      "RFC Recall: 0.219\n",
      "LG Recall: 0.204\n",
      "XGB Recall: 0.306\n",
      "Ethnicity: Hispanic\n",
      "RFC Recall: 0.133\n",
      "LG Recall: 0.178\n",
      "XGB Recall: 0.289\n",
      "Ethnicity: Native American\n",
      "RFC Recall: 0.333\n",
      "LG Recall: 0.222\n",
      "XGB Recall: 0.556\n",
      "Ethnicity: Other/Unknown\n",
      "RFC Recall: 0.154\n",
      "LG Recall: 0.179\n",
      "XGB Recall: 0.256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Define a dictionary to map ethnicity names to their corresponding boolean columns\n",
    "ethnicity_columns = {\n",
    "    'Asian': 'ethnicity_Asian',\n",
    "    'Caucasian': 'ethnicity_Caucasian',\n",
    "    'Hispanic': 'ethnicity_Hispanic',\n",
    "    'Native American': 'ethnicity_Native American',\n",
    "    'Other/Unknown': 'ethnicity_Other/Unknown'\n",
    "}\n",
    "\n",
    "# Loop through each ethnicity and evaluate accuracy\n",
    "for ethnicity, column_name in ethnicity_columns.items():\n",
    "    # Filter test data based on the ethnicity column\n",
    "    mask = X_test[column_name] == 1  # Filter for rows where the ethnicity column is 1 (True)\n",
    "    X_test_ethnicity = X_test[mask]\n",
    "    y_test_ethnicity = y_test[mask]\n",
    "    \n",
    "    #Calculate Recall, F1 and Area under ROC curve for each model\n",
    "    rfc_recall = recall_score(y_test_ethnicity, rfc.predict(X_test_ethnicity))\n",
    "    lg_recall = recall_score(y_test_ethnicity, lg.predict(X_test_ethnicity))\n",
    "    xgb_recall = recall_score(y_test_ethnicity, xgb.predict(X_test_ethnicity))\n",
    "\n",
    "    print(f\"Ethnicity: {ethnicity}\")\n",
    "    # Uncomment to reveal values\n",
    "    print(f\"RFC Recall: {round(rfc_recall, 3)}\")\n",
    "    print(f\"LG Recall: {round(lg_recall, 3)}\")\n",
    "    print(f\"XGB Recall: {round(xgb_recall, 3)}\")\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "158c9047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnicity: Asian\n",
      "RFC F1 score: 0.245\n",
      "LG F1 score: 0.255\n",
      "XGB F1 score: 0.364\n",
      "Ethnicity: Caucasian\n",
      "RFC F1 score: 0.245\n",
      "LG F1 score: 0.255\n",
      "XGB F1 score: 0.364\n",
      "Ethnicity: Hispanic\n",
      "RFC F1 score: 0.245\n",
      "LG F1 score: 0.255\n",
      "XGB F1 score: 0.364\n",
      "Ethnicity: Native American\n",
      "RFC F1 score: 0.245\n",
      "LG F1 score: 0.255\n",
      "XGB F1 score: 0.364\n",
      "Ethnicity: Other/Unknown\n",
      "RFC F1 score: 0.245\n",
      "LG F1 score: 0.255\n",
      "XGB F1 score: 0.364\n"
     ]
    }
   ],
   "source": [
    "for ethnicity, column_name in ethnicity_columns.items():\n",
    "    rfc_f1 = f1_score(y_test_ethnicity, rfc.predict(X_test_ethnicity))\n",
    "    lg_f1 = f1_score(y_test_ethnicity, lg.predict(X_test_ethnicity))\n",
    "    xgb_f1 = f1_score(y_test_ethnicity, xgb.predict(X_test_ethnicity))\n",
    "\n",
    "    print(f\"Ethnicity: {ethnicity}\")\n",
    "    print(f\"RFC F1 score: {round(rfc_f1, 3)}\")\n",
    "    print(f\"LG F1 score: {round(lg_f1, 3)}\")\n",
    "    print(f\"XGB F1 score: {round(xgb_f1, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "62291e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnicity: Asian\n",
      "RFC Area under ROC: 0.572\n",
      "LG Area under ROC: 0.579\n",
      "XGB Area under ROC: 0.621\n",
      "Ethnicity: Caucasian\n",
      "RFC Area under ROC: 0.572\n",
      "LG Area under ROC: 0.579\n",
      "XGB Area under ROC: 0.621\n",
      "Ethnicity: Hispanic\n",
      "RFC Area under ROC: 0.572\n",
      "LG Area under ROC: 0.579\n",
      "XGB Area under ROC: 0.621\n",
      "Ethnicity: Native American\n",
      "RFC Area under ROC: 0.572\n",
      "LG Area under ROC: 0.579\n",
      "XGB Area under ROC: 0.621\n",
      "Ethnicity: Other/Unknown\n",
      "RFC Area under ROC: 0.572\n",
      "LG Area under ROC: 0.579\n",
      "XGB Area under ROC: 0.621\n"
     ]
    }
   ],
   "source": [
    "for ethnicity, column_name in ethnicity_columns.items(): \n",
    "    rfc_auc = roc_auc_score(y_test_ethnicity, rfc.predict(X_test_ethnicity))\n",
    "    lg_auc = roc_auc_score(y_test_ethnicity, lg.predict(X_test_ethnicity))\n",
    "    xgb_auc = roc_auc_score(y_test_ethnicity, xgb.predict(X_test_ethnicity))\n",
    "    \n",
    "    print(f\"Ethnicity: {ethnicity}\")\n",
    "    print(f\"RFC Area under ROC: {round(rfc_auc, 3)}\")\n",
    "    print(f\"LG Area under ROC: {round(lg_auc, 3)}\")\n",
    "    print(f\"XGB Area under ROC: {round(xgb_auc, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bab498",
   "metadata": {},
   "source": [
    "Recall, F1 and Area under ROC for Males and Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bbfb2348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Recall for Male: 0.207\n",
      "LG Recall for Male: 0.205\n",
      "XGB Recall for Male: 0.318\n",
      "RFC Recall for female: 0.232\n",
      "LG Recall for female: 0.21\n",
      "XGB Recall for female: 0.291\n"
     ]
    }
   ],
   "source": [
    "filter_m = X_test['gender_M'] == 1\n",
    "\n",
    "rfc_recall = recall_score(y_test[filter_m], rfc.predict(X_test[filter_m]))\n",
    "lg_recall = recall_score(y_test[filter_m], lg.predict(X_test[filter_m]))\n",
    "xgb_recall = recall_score(y_test[filter_m], xgb.predict(X_test[filter_m]))\n",
    "\n",
    "print(\"RFC Recall for Male:\", round(rfc_recall, 3))\n",
    "print(\"LG Recall for Male:\", round(lg_recall, 3))\n",
    "print(\"XGB Recall for Male:\", round(xgb_recall, 3))\n",
    "\n",
    "rfc_recall = recall_score(y_test[~filter_m], rfc.predict(X_test[~filter_m]))\n",
    "lg_recall = recall_score(y_test[~filter_m], lg.predict(X_test[~filter_m]))\n",
    "xgb_recall = recall_score(y_test[~filter_m], xgb.predict(X_test[~filter_m]))\n",
    "\n",
    "print(\"RFC Recall for female:\", round(rfc_recall,3))\n",
    "print(\"LG Recall for female:\", round(lg_recall, 3))\n",
    "print(\"XGB Recall for female:\", round(xgb_recall, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "25031780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC f1 for Male: 0.321\n",
      "LG f1 for Male: 0.309\n",
      "XGB f1 for Male: 0.422\n",
      "RFC f1 for female: 0.349\n",
      "LG f1 for female: 0.314\n",
      "XGB f1 for female: 0.383\n"
     ]
    }
   ],
   "source": [
    "filter_m = X_test['gender_M'] == 1\n",
    "\n",
    "rfc_f1 = f1_score(y_test[filter_m], rfc.predict(X_test[filter_m]))\n",
    "lg_f1 = f1_score(y_test[filter_m], lg.predict(X_test[filter_m]))\n",
    "xgb_f1 = f1_score(y_test[filter_m], xgb.predict(X_test[filter_m]))\n",
    "\n",
    "print(\"RFC f1 for Male:\", round(rfc_f1, 3))\n",
    "print(\"LG f1 for Male:\", round(lg_f1, 3))\n",
    "print(\"XGB f1 for Male:\", round(xgb_f1, 3))\n",
    "\n",
    "rfc_f1 = f1_score(y_test[~filter_m], rfc.predict(X_test[~filter_m]))\n",
    "lg_f1 = f1_score(y_test[~filter_m], lg.predict(X_test[~filter_m]))\n",
    "xgb_f1 = f1_score(y_test[~filter_m], xgb.predict(X_test[~filter_m]))\n",
    "\n",
    "print(\"RFC f1 for female:\", round(rfc_f1, 3))\n",
    "print(\"LG f1 for female:\", round(lg_f1, 3))\n",
    "print(\"XGB f1 for female:\", round(xgb_f1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3004708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC ROCAUC for Male: 0.6\n",
      "LG ROCAUC for Male: 0.597\n",
      "XGB ROCAUC for Male: 0.65\n",
      "RFC ROCAUC for female: 0.612\n",
      "LG ROCAUC for female: 0.599\n",
      "XGB ROCAUC for female: 0.635\n"
     ]
    }
   ],
   "source": [
    "filter_m = X_test['gender_M'] == 1\n",
    "\n",
    "rfc_roc = roc_auc_score(y_test[filter_m], rfc.predict(X_test[filter_m]))\n",
    "lg_roc = roc_auc_score(y_test[filter_m], lg.predict(X_test[filter_m]))\n",
    "xgb_roc = roc_auc_score(y_test[filter_m], xgb.predict(X_test[filter_m]))\n",
    "\n",
    "print(\"RFC ROCAUC for Male:\", round(rfc_roc, 3))\n",
    "print(\"LG ROCAUC for Male:\", round(lg_roc, 3))\n",
    "print(\"XGB ROCAUC for Male:\", round(xgb_roc, 3))\n",
    "\n",
    "rfc_roc = roc_auc_score(y_test[~filter_m], rfc.predict(X_test[~filter_m]))\n",
    "lg_roc = roc_auc_score(y_test[~filter_m], lg.predict(X_test[~filter_m]))\n",
    "xgb_roc = roc_auc_score(y_test[~filter_m], xgb.predict(X_test[~filter_m]))\n",
    "\n",
    "print(\"RFC ROCAUC for female:\", round(rfc_roc, 3))\n",
    "print(\"LG ROCAUC for female:\", round(lg_roc, 3))\n",
    "print(\"XGB ROCAUC for female:\", round(xgb_roc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8730715",
   "metadata": {},
   "source": [
    "CONSTRAINED LEARNING OF BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e84389cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB performs best overall so far\n",
    "import xgboost as xgb\n",
    "\n",
    "# Calculate class weights for XGBoost\n",
    "class_weights_xgb = len(df_training[df_training['hospital_death'] == 0]) / len(df_training[df_training['hospital_death'] == 1])\n",
    "\n",
    "# Define XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'scale_pos_weight': class_weights_xgb,  # Set scale_pos_weight to the calculated class weight\n",
    "}\n",
    "\n",
    "# Convert data to DMatrix format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_weighed = xgb.train(params, dtrain)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred_proba = xgb_weighed.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dcc708",
   "metadata": {},
   "source": [
    "TESTING OF REWEIGHED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "584e7af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Training Set: 0.4010240468135686\n",
      "Recall on Training Set: 0.693109987357775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_proba = xgb_weighed.predict(dtrain)\n",
    "y_train_pred = (y_train_pred_proba > 0.65).astype(int)  # Assuming threshold of 0.5\n",
    "\n",
    "# Compute precision and recall\n",
    "precision = precision_score(y_train, y_train_pred)\n",
    "recall = recall_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"Precision on Training Set:\", precision)\n",
    "print(\"Recall on Training Set:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d6e6ae",
   "metadata": {},
   "source": [
    "Metrics for each sensitive group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f7f90e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Training Set: 0.26767452200978215\n",
      "Recall on Training Set: 0.7610619469026548\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision on Training Set:\", precision)\n",
    "print(\"Recall on Training Set:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f7b20ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache recall: 0.3008849557522124\n",
      "Apache Area under ROC: 0.6401811725426139\n",
      "Apache precision: 0.5804878048780487\n"
     ]
    }
   ],
   "source": [
    "y_apache_test_bin = (y_apache_test > 0.5).astype(int)\n",
    "apache_recall = recall_score(y_test, y_apache_test_bin)\n",
    "apache_roc = roc_auc_score(y_test, y_apache_test_bin)\n",
    "apache_precision = precision_score(y_test, y_apache_test_bin)\n",
    "\n",
    "print(\"Apache recall:\", apache_recall)\n",
    "print(\"Apache Area under ROC:\", apache_roc)\n",
    "print(\"Apache precision:\", apache_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a11c0559-19fd-4be4-99c1-3b9f359515a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The length of stay of the patient between hospital admission and unit admission'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wids.iloc[10:20]\n",
    "wids.loc[16, 'Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This part is to check the randomness of the data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmissingno\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmsno\u001b[39;00m\n\u001b[0;32m      3\u001b[0m msno\u001b[38;5;241m.\u001b[39mmatrix(df_training)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "# This part is to check the randomness of the data\n",
    "import missingno as msno\n",
    "msno.matrix(df_training)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
